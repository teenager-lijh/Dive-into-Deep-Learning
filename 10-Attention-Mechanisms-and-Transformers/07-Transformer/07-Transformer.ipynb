{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class PositionWiseFFN(nn.Module):\n",
    "    \"\"\"基于位置的前馈网络\"\"\"\n",
    "    def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs,\n",
    "                 **kwargs):\n",
    "        super(PositionWiseFFN, self).__init__(**kwargs)\n",
    "        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.dense2(self.relu(self.dense1(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3349, -0.2140, -0.3565,  0.3605,  0.3905,  0.4985,  0.2844,  0.3959],\n",
       "        [ 0.3349, -0.2140, -0.3565,  0.3605,  0.3905,  0.4985,  0.2844,  0.3959],\n",
       "        [ 0.3349, -0.2140, -0.3565,  0.3605,  0.3905,  0.4985,  0.2844,  0.3959]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffn = PositionWiseFFN(4, 4, 8)\n",
    "ffn.eval()\n",
    "ffn(torch.ones((2, 3, 4)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer norm: tensor([[-1.0000,  1.0000],\n",
      "        [-1.0000,  1.0000]], grad_fn=<NativeLayerNormBackward0>) \n",
      "batch norm: tensor([[-1.0000, -1.0000],\n",
      "        [ 1.0000,  1.0000]], grad_fn=<NativeBatchNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ln = nn.LayerNorm(2)\n",
    "bn = nn.BatchNorm1d(2)\n",
    "X = torch.tensor([[1, 2], [2, 3]], dtype=torch.float32)\n",
    "# 在训练模式下计算X的均值和方差\n",
    "print('layer norm:', ln(X), '\\nbatch norm:', bn(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class AddNorm(nn.Module):\n",
    "    \"\"\"残差连接后进行层规范化\"\"\"\n",
    "    def __init__(self, normalized_shape, dropout, **kwargs):\n",
    "        super(AddNorm, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.ln = nn.LayerNorm(normalized_shape)\n",
    "\n",
    "    def forward(self, X, Y):\n",
    "        return self.ln(self.dropout(Y) + X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_norm = AddNorm([3, 4], 0.5)\n",
    "add_norm.eval()\n",
    "add_norm(torch.ones((2, 3, 4)), torch.ones((2, 3, 4))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class EncoderBlock(nn.Module):\n",
    "    \"\"\"Transformer编码器块\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "                 dropout, use_bias=False, **kwargs):\n",
    "        super(EncoderBlock, self).__init__(**kwargs)\n",
    "        self.attention = d2l.MultiHeadAttention(\n",
    "            key_size, query_size, value_size, num_hiddens, num_heads, dropout,\n",
    "            use_bias)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(\n",
    "            ffn_num_input, ffn_num_hiddens, num_hiddens)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "\n",
    "    def forward(self, X, valid_lens):\n",
    "        Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))\n",
    "        return self.addnorm2(Y, self.ffn(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 24])"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones((2, 100, 24))\n",
    "valid_lens = torch.tensor([3, 2])\n",
    "encoder_blk = EncoderBlock(24, 24, 24, 24, [100, 24], 24, 48, 8, 0.5)\n",
    "encoder_blk.eval()\n",
    "encoder_blk(X, valid_lens).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class TransformerEncoder(d2l.Encoder):\n",
    "    \"\"\"Transformer编码器\"\"\"\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size,\n",
    "                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                 num_heads, num_layers, dropout, use_bias=False, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        # vocab_size 是在 embedding 层中进行 one-hot 编码步骤用到的\n",
    "        # num_hiddens 是把输入到 embedding 的最后一个维度的每个元素展开成 num_hiddens 长的向量\n",
    "        # num_hiddens 代表每个词元 使用 num_hiddens 长度的向量表示\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        # 对输入的数据添加位置编码\n",
    "        self.pos_encoding = d2l.PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\"block\"+str(i),\n",
    "                EncoderBlock(key_size, query_size, value_size, num_hiddens,\n",
    "                             norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                             num_heads, dropout, use_bias))\n",
    "\n",
    "    def forward(self, X, valid_lens, *args):\n",
    "        # 因为位置编码值在-1和1之间，\n",
    "        # 因此嵌入值乘以嵌入维度的平方根进行缩放，\n",
    "        # 然后再与位置编码相加。\n",
    "        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n",
    "        self.attention_weights = [None] * len(self.blks)\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X = blk(X, valid_lens)\n",
    "            self.attention_weights[i] = blk.attention.attention.attention_weights\n",
    "\n",
    "        # X 是经过 Encoder 汇聚之后的结果\n",
    "        # X 包含了所有的输入信息，但又不是全都包含在了一个像是 RNN 的 state 矩阵中\n",
    "        # 把 X 丢给 Encoder 的第二个注意力层后，由这个注意力层来选择使用哪些信息\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 24])"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = TransformerEncoder(\n",
    "    200, 24, 24, 24, 24, [100, 24], 24, 48, 8, 2, 0.5)\n",
    "encoder.eval()\n",
    "encoder(torch.ones((2, 100), dtype=torch.long), valid_lens).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    \"\"\"解码器中第i个块\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "                 dropout, i, **kwargs):\n",
    "        super(DecoderBlock, self).__init__(**kwargs)\n",
    "        self.i = i  # 存一下自己是第几个块\n",
    "        self.attention1 = d2l.MultiHeadAttention(\n",
    "            key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)  # norm 应该等于 num_hiddens 吧\n",
    "        self.attention2 = d2l.MultiHeadAttention(\n",
    "            key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens,  # ffn_num_input 应该等于 num_hiddens 把\n",
    "                                   num_hiddens)\n",
    "        self.addnorm3 = AddNorm(norm_shape, dropout)  # norm_shape 应该等于 num_hiddens 吧\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        # X (batch_size, num_steps, embedding_size=num_hiddens)\n",
    "        # decoder_block 拿到的输入 X 是原始样本经过 embedding 后的产物\n",
    "        enc_outputs, enc_valid_lens = state[0], state[1]\n",
    "        # 训练阶段，输出序列的所有词元都在同一时间处理，\n",
    "        # 因此state[2][self.i]初始化为None。\n",
    "        # 预测阶段，输出序列是通过词元一个接着一个解码的，\n",
    "        # 因此state[2][self.i]包含着直到当前时间步第i个块解码的输出表示\n",
    "\n",
    "        # state[2] 中的 [self.i] 并不是代表第 i 个时刻的东西\n",
    "        # 而是 第i个 Decoder 块的输入数据\n",
    "        # 在第 0 号时间步的数据进行前向运算的时候 state[2][...] 所有位置都是 None\n",
    "        # 因此在计算第 0 号时间步前向运算时，是第一次在 state[2][...] 中填充内容(对于每个样本序列而言，仅填充了一行)\n",
    "        # 接着计算后边的时间步的数值进行前向运算的时候 只需要把当前层的输入往下进行拼接即可\n",
    "\n",
    "        # state[2] 对于训练的过程没有什么帮助\n",
    "        # 在预测的时候才有帮助，因为预测的时候，每个时间步产生的每一个 Decoder-Block 的输出是一个时间步一个时间步产生的\n",
    "        # 而每次让 q 和所有的 k 做运算的时候，是需要把之前上一层的 Decoder-Block 产生的内容作为下一层 Decoder-Block 中\n",
    "        # 的 Attention 机制的 key-values pairs 的输入的，所以需要把之前时间步产生的 key-value 对给保存下来\n",
    "        \n",
    "        # 这同时也解释了，为什么在预测的时候不需要 valid_lens, 因为在 state[2] 中保存的 key_value 也就只有那么点\n",
    "        # 也就只有目前能够看到的序列产生的输出作为 key_value pairs 而后边的 key_value pairs 根本没存进去呢\n",
    "        \n",
    "        # 另外也能够解释为什么在训练的时候需要使用 valid_lens，因为在训练的时候一次性的，所有时间步的值都可以并行的作为输入\n",
    "        # 而 Self-Attention 计算第 i 个 q 的输出并不需要非得把前边的那些 q 都计算完了才能计算第 i 个 q\n",
    "        # 仅需要有所有的 key_values pairs 就可以计算任意一个 q 产生的输出了，这个不像 RNN 只能串行计算，而是可以并行计算\n",
    "        # 因此，一次性就输入进模型所有的 key_values pairs 了，这时候计算第 i 个 q 的时候与每一个 k 都进行了 dot product\n",
    "        # 但是，按照预测的逻辑来看，计算第 i 个 q 的 dot product 的时候，i 到 num_steps 的这些 q 产生的输出还不存在呢\n",
    "        # 但是在训练的时候这些 q 却可以被看到，因此就需要 valid_lens 来指明当前的 q 只能看到前多少个 key_values pairs\n",
    "\n",
    "        if state[2][self.i] is None:\n",
    "            key_values = X\n",
    "        else:\n",
    "            key_values = torch.cat((state[2][self.i], X), axis=1)\n",
    "        state[2][self.i] = key_values\n",
    "        if self.training:  # 应该是 net.train() 起的作用；把 self.training 设置为 True\n",
    "            batch_size, num_steps, _ = X.shape  # _ 是 embedding_size\n",
    "            # dec_valid_lens的开头:(batch_size,num_steps),\n",
    "            # 其中每一行是[1,2,...,num_steps]\n",
    "            # dec_valid_lens 是一个矩阵\n",
    "            # 做注意力机制的时候，每一个序列中的第 i 个 q 只能和这个序列的前 i 个 k 进行得分计算\n",
    "            # 因此就是 [1,2,...,num_steps]\n",
    "            dec_valid_lens = torch.arange(\n",
    "                1, num_steps + 1, device=X.device).repeat(batch_size, 1)\n",
    "        else:\n",
    "            dec_valid_lens = None\n",
    "\n",
    "        # 自注意力\n",
    "        # 做注意力机制的时候，每一个序列中的第 i 个 q 只能和这个序列的前 i 个 k 进行得分计算\n",
    "        X2 = self.attention1(X, key_values, key_values, dec_valid_lens)\n",
    "        Y = self.addnorm1(X, X2)\n",
    "        # 编码器－解码器注意力。\n",
    "        # enc_outputs的开头:(batch_size,num_steps,num_hiddens)\n",
    "        Y2 = self.attention2(Y, enc_outputs, enc_outputs, enc_valid_lens)\n",
    "        Z = self.addnorm2(Y, Y2)\n",
    "        return self.addnorm3(Z, self.ffn(Z)), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 24])"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_blk = DecoderBlock(24, 24, 24, 24, [100, 24], 24, 48, 8, 0.5, 0)\n",
    "decoder_blk.eval()\n",
    "X = torch.ones((2, 100, 24))\n",
    "state = [encoder_blk(X, valid_lens), valid_lens, [None]]\n",
    "decoder_blk(X, state)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(d2l.AttentionDecoder):\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size,\n",
    "                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                 num_heads, num_layers, dropout, **kwargs):\n",
    "        super(TransformerDecoder, self).__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.pos_encoding = d2l.PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\"block\"+str(i),\n",
    "                DecoderBlock(key_size, query_size, value_size, num_hiddens,\n",
    "                             norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                             num_heads, dropout, i))\n",
    "        self.dense = nn.Linear(num_hiddens, vocab_size)\n",
    "\n",
    "    def init_state(self, enc_outputs, enc_valid_lens, *args):\n",
    "        return [enc_outputs, enc_valid_lens, [None] * self.num_layers]\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n",
    "        self._attention_weights = [[None] * len(self.blks) for _ in range (2)]\n",
    "        for i, blk in enumerate(self.blks):  # i 代表的是第 i 号块，而 state[2][i] 确实是第 i 个块的输入，且是第 i-1 号块的输出\n",
    "            X, state = blk(X, state)\n",
    "            # 解码器自注意力权重\n",
    "            self._attention_weights[0][i] = blk.attention1.attention.attention_weights\n",
    "            # “编码器－解码器”自注意力权重\n",
    "            self._attention_weights[1][i] = blk.attention2.attention.attention_weights\n",
    "        return self.dense(X), state\n",
    "\n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        return self._attention_weights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hiddens, num_layers, dropout, batch_size, num_steps = 32, 2, 0.1, 64, 10\n",
    "lr, num_epochs, device = 0.005, 200, d2l.try_gpu()\n",
    "ffn_num_input, ffn_num_hiddens, num_heads = 32, 64, 4\n",
    "key_size, query_size, value_size = 32, 32, 32\n",
    "norm_shape = [32]\n",
    "\n",
    "train_iter, src_vocab, tgt_vocab = d2l.load_data_nmt(batch_size, num_steps)\n",
    "\n",
    "# encoder = TransformerEncoder(\n",
    "#     len(src_vocab), key_size, query_size, value_size, num_hiddens,\n",
    "#     norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "#     num_layers, dropout)\n",
    "# decoder = TransformerDecoder(\n",
    "#     len(tgt_vocab), key_size, query_size, value_size, num_hiddens,\n",
    "#     norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "#     num_layers, dropout)\n",
    "net = d2l.EncoderDecoder(encoder, decoder)\n",
    "\n",
    "# 编码器的输入是一个二维的样本矩阵 X 每一行都是一个句子\n",
    "# 解码器的输入 dec_input 也是一个样本矩阵，每一行都是一个句子并且有开始标志 <bos> 是在训练的时候添加上的\n",
    "d2l.train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])  and  torch.Size([64, 10])\n",
      "tensor([[ 7, 10,  4,  3,  1,  1,  1,  1,  1,  1],\n",
      "        [30, 38,  4,  3,  1,  1,  1,  1,  1,  1],\n",
      "        [ 9, 28,  5,  3,  1,  1,  1,  1,  1,  1]])\n",
      "tensor([[  6,   7,   8,   4,   3,   1,   1,   1,   1,   1],\n",
      "        [148,   5,   3,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [ 59,   5,   3,   1,   1,   1,   1,   1,   1,   1]])\n",
      "<pad>\n",
      "<pad>\n",
      "tensor([4, 4, 4])\n",
      "tensor([5, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "for X, X_valid_lens, Y, Y_valid_lens in train_iter:\n",
    "    print(X.shape, ' and ', Y.shape)\n",
    "    print(X[:3, :])\n",
    "    print(Y[:3, :])\n",
    "    print(src_vocab.idx_to_token[1])\n",
    "    print(tgt_vocab.idx_to_token[1])\n",
    "    print(X_valid_lens[:3])\n",
    "    print(Y_valid_lens[:3])\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 计算 BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engs = ['go .', \"i lost .\", 'he\\'s calm .', 'i\\'m home .']\n",
    "# fras = ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .']\n",
    "# for eng, fra in zip(engs, fras):\n",
    "#     translation, dec_attention_weight_seq = d2l.predict_seq2seq(\n",
    "#         net, eng, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "#     print(f'{eng} => {translation}, ',\n",
    "#           f'bleu {d2l.bleu(translation, fra, k=2):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc_attention_weights = torch.cat(net.encoder.attention_weights, 0).reshape((num_layers, num_heads,\n",
    "#     -1, num_steps))\n",
    "# enc_attention_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d2l.show_heatmaps(\n",
    "#     enc_attention_weights.cpu(), xlabel='Key positions',\n",
    "#     ylabel='Query positions', titles=['Head %d' % i for i in range(1, 5)],\n",
    "#     figsize=(7, 3.5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 理解 Layer-Norm 和 Batch-Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([\n",
    "    [1, 2],\n",
    "    [2, 3]\n",
    "], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 传入一个整数 2 \n",
    "# 则参数被看作是一个只有一个元素 2 的 list\n",
    "# 代表对最后一个维度上长度为 2 的每个向量分别做归一化\n",
    "ln = nn.LayerNorm(2)\n",
    "bn = nn.BatchNorm1d(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.0000,  1.0000],\n",
       "         [-1.0000,  1.0000]], grad_fn=<NativeLayerNormBackward0>),\n",
       " tensor([[-1.0000, -1.0000],\n",
       "         [ 1.0000,  1.0000]], grad_fn=<NativeBatchNormBackward0>))"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Layer-Norm 是把矩阵中的每一行归一化（每行是一个样本中一个数值的向量表示）\n",
    "# Batch-Norm 是把矩阵中的每一列归一化（每列是一个样本中多个数值的相同特征）\n",
    "# 因此 波波老师 的视频中讲的 均值方差归一化 属于是 Batch-Norm\n",
    "ln(X), bn(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, var = torch.mean(X[0]), torch.var(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-1.), tensor(1.))"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1-mean) / var, (2-mean) / var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, var = torch.mean(X[1]), torch.var(X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-1.), tensor(1.))"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2-mean) / var, (3-mean) / var"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 理解 nn.Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 4],\n",
       "        [2, 3, 5]])"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.tensor([\n",
    "    [1, 2, 4],\n",
    "    [2, 3, 5]\n",
    "])\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.5088, -1.5678, -1.1260,  1.3037,  0.2724, -0.6884,  1.7257],\n",
       "          [-2.2114, -1.2187, -1.0790,  0.6996,  1.1503, -1.0259,  1.3760],\n",
       "          [-0.8085,  0.4052, -0.3968, -1.7356, -0.2481,  1.3400, -1.2124]],\n",
       " \n",
       "         [[-2.2114, -1.2187, -1.0790,  0.6996,  1.1503, -1.0259,  1.3760],\n",
       "          [-0.7309,  0.8472, -0.3097,  0.3759, -0.0202, -0.6070, -0.3054],\n",
       "          [-0.6857, -0.8837, -0.9190,  0.0105,  0.4702, -0.3287, -0.2345]]],\n",
       "        grad_fn=<EmbeddingBackward0>),\n",
       " torch.Size([2, 3, 7]))"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 6\n",
    "num_hiddens = 7\n",
    "\n",
    "\"\"\"\n",
    "embedding : (不确定内部是不是这样实现的)\n",
    "先对输入的序列中的每一个值做 one-hot\n",
    "在把每一个 one-hot 转化成一个连续类型的向量（做了一个全连接层）\n",
    "\n",
    "让 embedding 层学习到词和词之间的关系\n",
    "经过 embedding 层输出的是一个实数向量\n",
    "这样的一个向量表示的肯定不只是曾经 one-hot 表示的单个词的信息了\n",
    "从而就学习到了词和词之间的关系（联系）信息\n",
    "而且 embedding 的输出也不必和 词元个数(vocab_size) 相同，可以比 vocab_size 大，\n",
    "因为它承载了更多的内容\n",
    "\"\"\"\n",
    "\n",
    "# 通过 Embedding 的方式把句子中的每一个词元向量化表示\n",
    "embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "embedding(inputs), embedding(inputs).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 理解 torch.cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3,  4],\n",
       "         [ 5,  6,  7,  8],\n",
       "         [ 2,  2,  3,  4],\n",
       "         [ 2,  6,  7,  8]],\n",
       "\n",
       "        [[ 1,  2,  3,  4],\n",
       "         [ 1,  2,  3,  4],\n",
       "         [22,  2,  3,  4],\n",
       "         [22,  2,  3,  4]]])"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = torch.tensor([\n",
    "[\n",
    "    [1, 2, 3, 4],\n",
    "    [5, 6, 7, 8]\n",
    "],\n",
    "[\n",
    "    [1, 2, 3, 4],\n",
    "    [1, 2, 3, 4]\n",
    "]\n",
    "])\n",
    "\n",
    "X2 = torch.tensor([\n",
    "[\n",
    "    [2, 2, 3, 4],\n",
    "    [2, 6, 7, 8]\n",
    "],\n",
    "[\n",
    "    [22, 2, 3, 4],\n",
    "    [22, 2, 3, 4]\n",
    "]\n",
    "])\n",
    "\n",
    "# 在第 1 号轴的方向上进行拼接，横着拼\n",
    "# 对应模型中的 key_values 也是三维的\n",
    "# (batch_size, num_key_values_pairs, num_hiddens)\n",
    "# 每次都扩展 key_values，把之前输入的内容 concat 到 axis=1 上去\n",
    "res = torch.cat((X1, X2), axis=1)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 2, 4]), torch.Size([2, 2, 4]))"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape, X2.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 理解 torch.arange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [1, 2],\n",
       "        [1, 2],\n",
       "        [1, 2]])"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 生成 1 到 3 之间的整数作为一个向量\n",
    "# 把这个向量在 0 号维度复制 4 次 得到一个矩阵\n",
    "# 把这个矩阵在 1 号维度复制 1 次 拼接起来\n",
    "dec_valid_lens = torch.arange(1, 3).repeat(4, 1)\n",
    "dec_valid_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "86bb26bcf3701c754d5fd40db657c5b7e15a074c1099b32f8fc32052c18ad091"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
