## 门控循环单元 GRU

门控制单元是在 LSTM 之后提出的

![](01-Gated-Recurrent-Units (GRU).assets/image-20221101110806989.png)

RNN 神经网络没有对于信息重要性的筛查，门控循环单元是对信息重要程度的筛选



## 两种门

![](01-Gated-Recurrent-Units (GRU).assets/image-20221101111155976.png)



通过输入 $X$ 和 状态 $H$ 计算出 $R$ 和 $Z$ 

$\sigma$ 是 $sigmoid$ 函数，会把数值变换到 $(0, 1)$ 之间

![](01-Gated-Recurrent-Units (GRU).assets/image-20221101111622923.png)



## 候选隐状态

**符号**：圆圈加一个点，代表按元素点乘

在 RNN 网络计算下一次的隐藏状时，在下图的蓝色方框中的 $R_t$ 等于 1 ，代表上一次的状态 $H_{t-1}$ 的信息全都要。而这里的 $R_t$ 变成了 $(0,1)$ 之间的一个数值，对于以往的信息是否保留有了选择。

（这里讨论的是候选隐状态而不是真正的隐藏状态）

对于门，可以阻挡，可以释放，而这里的是一个 0 到 1 的门，是一个如软门，可以控制释放过去的量

note: $H_t$ 和 $R_t$ 都是向量，而不是一个标量，使用向量表达了上一次的隐藏状态 

![](01-Gated-Recurrent-Units (GRU).assets/image-20221101112204829.png)



## 隐状态

1. 当 $Z_t=1$ 的时候，只要过去的状态，相当于没有更新，直接把以前的状态给拿过来了
2. 当 $Z_t = 0$ 的时候，只要更新的状态，相当于丢弃了过去所有的信息 ，只看当下

 

![](01-Gated-Recurrent-Units (GRU).assets/image-20221101141801465.png)



## 总结

![](01-Gated-Recurrent-Units (GRU).assets/image-20221101142917740.png)